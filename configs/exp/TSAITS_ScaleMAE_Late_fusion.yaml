# @package _global_

defaults:
  - override /model/network: Late_fusion_ScaleMAE
  - override /dataset/train_transform: MAE 
  - override /dataset/test_transform: MAE

model:
  name: "ScaleMAE_Late_fusion"
  optimizer:
    lr: 2e-4
  network:
    instance:
      encoder:
        aerial:
          path: ${paths.log_dir}/TreeSat_ScaleMAE_Aerial/checkpoints/last.ckpt
        s2-4season-median:
          _target_: models.networks.Fine_tuning_MAE.Fine
          path: ${paths.log_dir}/TreeSat_ScaleMAE_S2-4s/checkpoints/last.ckpt
          encoder: 
            _target_: models.networks.encoder.ScaleViT.ScaleVitEncoder
            img_size: 48
            patch_size: 8
            channel_groups: [[0, 1, 2, 6], [3, 4, 5, 7], [8, 9], [10, 11, 12, 16], [13, 14, 15, 17], [18, 19], [20, 21, 22, 26], [23, 24, 25, 27], [28, 29], [30, 31, 32, 36], [33, 34, 35, 37], [38, 39]]
            channel_group_gsds: [10, 20, 20, 10, 20, 20, 10, 20, 20, 10, 20, 20]
            in_chans: 40
            embed_dim: 384
            depth: 12
            num_heads: 16
            mlp_ratio: 4.
            modalities: ["s2-4season-median"]
          output_size: 384
          inter_dim: []
          p_drop: 0.2
          freeze: False
          n_class: 128
          modalities: ["s2-4season-median"]
          last_block: False
          pooling_method: 'token'
    mlp:
      instance:
        initial_dim: 256

dataset:
  train_transform:
    s2_size: 48
  test_transform:
    s2_size: 48

callbacks:
  early_stopping:
    monitor: "val/F1_Score_macro"
    mode: "max"
    patience: 10

modalities:
  - "aerial"
  - "s2-4season-median"
